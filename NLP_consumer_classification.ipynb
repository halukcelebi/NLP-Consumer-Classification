{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89997073",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data source: https://thecleverprogrammer.com/2022/11/28/consumer-complaint-classification-with-machine-learning/\n",
    "\n",
    "In this project it is expected to classify consumer complaint. Output of the data is\n",
    "'Product' which basically explains what consumers issue is about. I applied NLP\n",
    "techniques we learnt in the course, classify consumer complaints. \n",
    "Original data has over 3 million rows, I used 50k rows in my project. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eddcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a6c519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"consumercomplaints.csv\")\n",
    "#df = df['Consumer complaint narrative'].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9660d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA/ DATA MANIPULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680aa427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c0192c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d1c3d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>964553</th>\n",
       "      <td>964553</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Problem with a credit reporting company's inve...</td>\n",
       "      <td>Was not notified of investigation status or re...</td>\n",
       "      <td>I decided to get my credit pulled due to a bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010276</th>\n",
       "      <td>1010276</td>\n",
       "      <td>2017-05-20</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account information incorrect</td>\n",
       "      <td>On  XXXX   2017 , I paid Barclay card a settle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231896</th>\n",
       "      <td>1231896</td>\n",
       "      <td>2016-05-03</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional adjustable mortgage (ARM)</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My financial hardship began on XX/XX/XXXX when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961318</th>\n",
       "      <td>961318</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>Credit card or prepaid card</td>\n",
       "      <td>General-purpose credit card or charge card</td>\n",
       "      <td>Other features, terms, or problems</td>\n",
       "      <td>Problem with rewards from credit card</td>\n",
       "      <td>I had an American Express Business Platinum ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448317</th>\n",
       "      <td>2448317</td>\n",
       "      <td>2021-11-12</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account status incorrect</td>\n",
       "      <td>I am XXXX XXXX XXXX and I am submitting this c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 Date received  \\\n",
       "964553       964553    2020-07-13   \n",
       "1010276     1010276    2017-05-20   \n",
       "1231896     1231896    2016-05-03   \n",
       "961318       961318    2019-01-25   \n",
       "2448317     2448317    2021-11-12   \n",
       "\n",
       "                                                   Product  \\\n",
       "964553   Credit reporting, credit repair services, or o...   \n",
       "1010276  Credit reporting, credit repair services, or o...   \n",
       "1231896                                           Mortgage   \n",
       "961318                         Credit card or prepaid card   \n",
       "2448317  Credit reporting, credit repair services, or o...   \n",
       "\n",
       "                                        Sub-product  \\\n",
       "964553                             Credit reporting   \n",
       "1010276                            Credit reporting   \n",
       "1231896      Conventional adjustable mortgage (ARM)   \n",
       "961318   General-purpose credit card or charge card   \n",
       "2448317                            Credit reporting   \n",
       "\n",
       "                                                     Issue  \\\n",
       "964553   Problem with a credit reporting company's inve...   \n",
       "1010276               Incorrect information on your report   \n",
       "1231896           Loan modification,collection,foreclosure   \n",
       "961318                  Other features, terms, or problems   \n",
       "2448317               Incorrect information on your report   \n",
       "\n",
       "                                                 Sub-issue  \\\n",
       "964553   Was not notified of investigation status or re...   \n",
       "1010276                      Account information incorrect   \n",
       "1231896                                                NaN   \n",
       "961318               Problem with rewards from credit card   \n",
       "2448317                           Account status incorrect   \n",
       "\n",
       "                              Consumer complaint narrative  \n",
       "964553   I decided to get my credit pulled due to a bil...  \n",
       "1010276  On  XXXX   2017 , I paid Barclay card a settle...  \n",
       "1231896  My financial hardship began on XX/XX/XXXX when...  \n",
       "961318   I had an American Express Business Platinum ca...  \n",
       "2448317  I am XXXX XXXX XXXX and I am submitting this c...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e5709d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                         0\n",
       "Date received                      0\n",
       "Product                            0\n",
       "Sub-product                     2291\n",
       "Issue                              0\n",
       "Sub-issue                       8630\n",
       "Consumer complaint narrative       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6f993c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50000 entries, 964553 to 2634106\n",
      "Data columns (total 7 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Unnamed: 0                    50000 non-null  int64 \n",
      " 1   Date received                 50000 non-null  object\n",
      " 2   Product                       50000 non-null  object\n",
      " 3   Sub-product                   47709 non-null  object\n",
      " 4   Issue                         50000 non-null  object\n",
      " 5   Sub-issue                     41370 non-null  object\n",
      " 6   Consumer complaint narrative  50000 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "98b03851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP - DATA CLEANING /PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6a3eee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kucuk harfe donustur\n",
    "df[\"Consumer complaint narrative\"]=df[\"Consumer complaint narrative\"].str.lower()\n",
    "# noktalama isaretlerini kaldirma\n",
    "df[\"Consumer complaint narrative\"]=df[\"Consumer complaint narrative\"].str.replace(\"[^\\w\\s]\",\"\") \n",
    "# rakamlari kaldir\n",
    "df[\"Consumer complaint narrative\"]=df[\"Consumer complaint narrative\"].str.replace(\"\\d+\",\"\") \n",
    "# \\newline ve enter\\r kaldir\n",
    "df[\"Consumer complaint narrative\"]=df[\"Consumer complaint narrative\"].str.replace(\"\\n\",\" \").replace(\"\\r\",\"\") \n",
    "df[\"Consumer complaint narrative\"]=df[\"Consumer complaint narrative\"].str.replace(\"  \",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a161c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip out html tags\n",
    "import html\n",
    "def del_html(text):\n",
    "   return html.unescape(text)\n",
    "\n",
    "# Apply to multiple columns\n",
    "df['Consumer complaint narrative'] = df['Consumer complaint narrative'].apply(del_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c87302b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\haluk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\haluk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\haluk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\haluk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Remove STOP words\n",
    "# Taken from Amazon \n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#import nltk resources\n",
    "resources = [\"wordnet\", \"stopwords\", \"punkt\", \\\n",
    "             \"averaged_perceptron_tagger\", \"maxent_treebank_pos_tagger\"]\n",
    "\n",
    "for resource in resources:\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/\" + resource)\n",
    "    except LookupError:\n",
    "        nltk.download(resource)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "22d4c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "stop_words = [word.replace(\"\\'\", \"\") for word in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "91f7644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import time\n",
    "\n",
    "i = 0;\n",
    "nan_index = []\n",
    "text_wo_sw = []\n",
    "for text in df['Consumer complaint narrative']:\n",
    "    \n",
    "    ret_str =\"\";\n",
    "    if isinstance(text, six.string_types):\n",
    "    \n",
    "        splitted_text = text.split(\" \");\n",
    "        for word in splitted_text:\n",
    "            #print(word)\n",
    "\n",
    "            if len(word)>0 and isinstance(word, six.string_types):\n",
    "                if word not in stop_words:\n",
    "                    ret_str = ret_str +\" \"+word\n",
    "                        \n",
    "            #else :\n",
    "                #print(word)\n",
    "                #print('not string')\n",
    "    else :\n",
    "        #print(i) \n",
    "        #print(text)\n",
    "        nan_index.append(i)\n",
    "        #print('not a string unfortunately')\n",
    "    \n",
    "    text_wo_sw.append(ret_str)\n",
    "    i=i+1;    \n",
    "df['Consumer complaint narrative'] =  text_wo_sw \n",
    "df.drop(df.index[nan_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4a4b9a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Credit reporting, credit repair services, or other personal consumer reports',\n",
       "       'Mortgage', 'Credit card or prepaid card', 'Credit card',\n",
       "       'Vehicle loan or lease', 'Consumer Loan',\n",
       "       'Money transfer, virtual currency, or money service',\n",
       "       'Debt collection', 'Checking or savings account', 'Student loan',\n",
       "       'Payday loan, title loan, or personal loan', 'Credit reporting',\n",
       "       'Bank account or service', 'Money transfers',\n",
       "       'Other financial service', 'Prepaid card', 'Payday loan',\n",
       "       'Virtual currency'], dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Product'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56882912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output product is verbal data. We quantify this data\n",
    "column = 'Product';\n",
    "#print(type(df[column]))\n",
    "value_counts = df[column].value_counts()\n",
    "num_categories = len(value_counts)\n",
    "# İki alt kategorisi varsa 0 ve 1 olarak kodlayalım\n",
    "if num_categories == 2:\n",
    "    category_mapping = {category: index for index, category in enumerate(value_counts.index)}\n",
    "    df[column] = df[column].map(category_mapping)\n",
    "# İki alt kategoriden fazlaysa 1'den başlayan sıralı sayılarla kodlayalım\n",
    "else:\n",
    "    category_mapping = {category: index + 1 for index, category in enumerate(value_counts.index)}\n",
    "    df[column] = df[column].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bdb4adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Consumer complaint narrative']\n",
    "y = df['Product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ac427828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "x =vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "56b2313c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 43654), (50000,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dd8a73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_test(x,y):\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    from scipy import stats\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline \n",
    "    import seaborn as sns\n",
    "\n",
    "\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "    from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso\n",
    "    from sklearn.tree import ExtraTreeClassifier\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from xgboost import XGBRegressor \n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    #plt.style.use('')\n",
    "\n",
    "    \n",
    "    G = GaussianNB()\n",
    "    B = BernoulliNB()\n",
    "    K = KNeighborsClassifier()\n",
    "    L = LogisticRegression()\n",
    "    D = DecisionTreeClassifier()\n",
    "    S = SVC()\n",
    "    SGD = SGDClassifier()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state = 13)\n",
    "    \n",
    "    #algos = [G,B,K,L,D,S]\n",
    "    algos = [G,B,K,L,D, SGD]\n",
    "    \n",
    "    #algo_names = [ \"Gaussian\", \"Bernoulli\", \"K-Neighbors\", \"Logistic Regression\", \"Decision Tree\",\"SVC\" ]\n",
    "    algo_names = [ \"Gaussian\", \"Bernoulli\", \"K-Neighbors\", \"Logistic Regression\", \"Decision Tree\", \\\n",
    "                  'Stochastic Gradient Descent' ]\n",
    "    \n",
    "    ASC = [];\n",
    "    \n",
    "    result =  result = pd.DataFrame(columns =['Accuracy_Score'], index = algo_names)\n",
    "    \n",
    "    i = 0;\n",
    "    for algo in algos :\n",
    "        \n",
    "        algo.fit(x_train,y_train)\n",
    "        print (accuracy_score(  y_test, algo.predict(x_test) ))\n",
    "        ASC.append(  accuracy_score(  y_test, algo.predict(x_test) ) )\n",
    "        \n",
    "        print( \"Confusion matrix: \",format(algo_names[i]) )\n",
    "        i = i+1;\n",
    "        print ( confusion_matrix(algo.predict(x_test),y_test) )\n",
    "        \n",
    "        #algo.fit(x,y)\n",
    "        #print (accuracy_score(  y, algo.predict(x) ))\n",
    "        #ASC.append(  accuracy_score(  y, algo.predict(x) ) )\n",
    "    \n",
    "    \n",
    "    result.Accuracy_Score = ASC;\n",
    "\n",
    "    return result.sort_values('Accuracy_Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "10b9ca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2807\n",
      "Confusion matrix:  Gaussian\n",
      "[[985 178 107 108  49  81  47  22  19  43  15  20  14   0   3   2   1   0]\n",
      " [511 613  67  71  38  68  32  15  28  31   6  19  17   0   2   0   0   0]\n",
      " [174  88 528  54  52  20  12  15  18  18  20  15  13   1   1   0   0   0]\n",
      " [335 126  27 210  69  11  30  29  40  12  10  15   5   1   1   2   0   0]\n",
      " [106  66  34  75 115   7   5  48  13   7  26  14   2   1   2   2   0   0]\n",
      " [148  50  14  13   5 104   6   1   3   3   2   2   0   0   0   0   0   0]\n",
      " [878 113   6  15   3  11  81   0   4   3   1   2   0   0   0   0   0   0]\n",
      " [ 56  21   6  25  37   2   1  80   4   1   3   1   0   1   1   1   0   0]\n",
      " [124  44   7  55  19   3   6   3  25   3   6   1   1   1   1   0   0   0]\n",
      " [147  47  20  14  12   3   6   1   0  22   3   7   4   1   0   0   0   0]\n",
      " [ 49  23  10  27  40   1   5   7   6   1  17   3   3   0   0   2   1   0]\n",
      " [475 100  15  42  23  10  18  13   6   8  13  11  10   1   0   1   0   0]\n",
      " [575 163  16  41  17   6  36   7  10  15   5  15  13   2   0   1   0   0]\n",
      " [ 41  19   0   7   3   0   1   0   1   1   0   1   0   1   0   0   0   0]\n",
      " [ 19   1   0   1   2   0   0   2   0   0   0   0   0   0   2   0   0   1]\n",
      " [ 22   5   0   1   0   1   1   2   1   0   0   0   0   0   0   0   0   0]\n",
      " [  9   8   0   0   1   0   0   1   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "0.6458\n",
      "Confusion matrix:  Bernoulli\n",
      "[[4141  624  174  226  109   99  235   72   56   61   38   43   30    5\n",
      "     6    3    1    1]\n",
      " [ 204  915   80   39   24   51   25   24   18   32   14   31   21    4\n",
      "     0    1    0    0]\n",
      " [ 111   74  586   22   14   56    7   11    7   51    7   31   22    1\n",
      "     0    0    0    0]\n",
      " [ 169   42   16  438   88    8   18   48   96   18   20   17    2    0\n",
      "     2    6    0    0]\n",
      " [   3    4    1   28  245    1    0   78    1    0   48    4    1    0\n",
      "     5    1    1    0]\n",
      " [  12    4    0    0    0  113    0    0    0    0    0    1    1    0\n",
      "     0    0    0    0]\n",
      " [   2    0    0    0    0    0    2    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    1    3    0    0   12    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    1    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   9    2    0    3    1    0    0    0    0    6    0    0    5    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    1    1    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   2    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n",
      "0.6963\n",
      "Confusion matrix:  K-Neighbors\n",
      "[[4367  649  151  230   98   75  245   42   45   80   23   62   38    3\n",
      "     2    2    0    0]\n",
      " [ 129  919   29   53   21   17   14   17   17   15    7   12   13    2\n",
      "     2    0    1    0]\n",
      " [  52   26  624   12   19   16    2    6    8   11    8   11    8    0\n",
      "     0    0    0    0]\n",
      " [  43   28   20  396   78   11    0   13   88   10   13   10    2    1\n",
      "     0    6    0    0]\n",
      " [  14    9   21   38  228    2    1   39    6    2   53    8    3    1\n",
      "     0    0    0    1]\n",
      " [  14   10    4    1    0  202    0    0    0    3    0    3    4    0\n",
      "     0    0    0    0]\n",
      " [  11    2    2    0    0    1   25    0    0    1    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   1    5    2   10   29    1    0  124    3    0    6    3    0    0\n",
      "     9    0    1    0]\n",
      " [   4    5    2   12    1    1    0    0   10    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [  13    8    0    2    0    0    0    0    0   42    1    6   10    0\n",
      "     0    0    0    0]\n",
      " [   2    0    0    1   11    0    0    3    1    0   14    1    0    0\n",
      "     0    1    0    0]\n",
      " [   3    2    1    4    0    0    0    2    0    2    1    9    3    3\n",
      "     0    0    0    0]\n",
      " [   1    1    1    0    0    2    0    0    0    2    0    2    1    0\n",
      "     0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    1    0    0    0\n",
      "     0    2    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n",
      "0.7794\n",
      "Confusion matrix:  Logistic Regression\n",
      "[[4277  302   53  127   25   31  233   14   28   58    9   35   19    0\n",
      "     0    1    0    0]\n",
      " [ 206 1288   13   44   10   28   24    7   17   23    4   20   20    3\n",
      "     1    0    1    0]\n",
      " [  48   19  775    2    4    9    3    1    1    6    5   12   11    0\n",
      "     0    0    0    0]\n",
      " [  53   25    7  532   49    6    3   13  114    6   12    9    0    0\n",
      "     0    7    0    0]\n",
      " [  13    8    3   36  369    1    0   56    5    1   78    9    1    1\n",
      "     0    1    0    0]\n",
      " [  22    6    2    1    0  252    1    0    1    1    0    3    1    0\n",
      "     0    0    0    0]\n",
      " [  13    2    0    0    0    0   22    0    0    0    1    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    1    5   25    1    0  154    2    0    5    2    1    1\n",
      "    12    0    1    1]\n",
      " [   0    1    0    7    0    0    0    0   10    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [  19    6    0    2    0    0    1    0    0   68    0    5   22    1\n",
      "     0    0    0    0]\n",
      " [   1    0    1    2    2    0    0    0    0    0   13    0    0    0\n",
      "     0    2    0    0]\n",
      " [   2    8    2    1    1    0    0    1    0    3    0   32    5    4\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    2    0    0    2    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n",
      "0.6594\n",
      "Confusion matrix:  Decision Tree\n",
      "[[3780  343   72  132   45   38  191   17   29   41   11   28   20    1\n",
      "     1    1    0    0]\n",
      " [ 343 1133   44   79   28   40   30   13   25   23    9   22   12    1\n",
      "     1    0    0    0]\n",
      " [  79   27  640   16   13   26    3   11    3    8    7   11    7    2\n",
      "     0    0    0    0]\n",
      " [ 123   33   15  373   62    7    7   25   72   10   19    7    2    1\n",
      "     2    6    0    0]\n",
      " [  38   15   14   53  223    3    1   62    8    9   50    4    1    1\n",
      "     3    0    1    0]\n",
      " [  37   24   15    5    3  194    4    0    3    1    2    6    4    1\n",
      "     0    0    0    0]\n",
      " [ 128   28    3    8    2    2   39    0    2    5    0    2    2    0\n",
      "     0    0    0    0]\n",
      " [  11    7   15   20   53    1    0   94    2    5    5    3    0    0\n",
      "     3    0    0    1]\n",
      " [  24   20    3   48    6    0    4    6   23    1    4    3    1    0\n",
      "     0    1    0    0]\n",
      " [  39   12    7   10    2    3    4    1    2   44    3   10   14    0\n",
      "     0    0    0    0]\n",
      " [  12    6    6    9   35    0    2   11    3    1   17    0    1    0\n",
      "     2    2    1    0]\n",
      " [  26   13   17    3    6    8    0    5    2    5    0   21    5    3\n",
      "     0    0    0    0]\n",
      " [  10    2    4    0    2    5    1    1    4   14    0    7   11    0\n",
      "     0    0    0    0]\n",
      " [   1    1    2    0    0    1    1    0    0    0    0    3    2    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    4    0    0    0    0    1    0    0    0    0\n",
      "     1    0    0    0]\n",
      " [   3    1    0    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0]\n",
      " [   0    0    0    0    1    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7739\n",
      "Confusion matrix:  Stochastic Gradient Descent\n",
      "[[4322  328   50  142   31   29  252   21   28   73   11   41   25    0\n",
      "     1    1    0    0]\n",
      " [ 192 1267   12   36   13   24   23    7   16   29    3   23   25    5\n",
      "     1    0    0    0]\n",
      " [  54   25  785    3    6    6    4    2    1    9    7   15   10    1\n",
      "     0    0    0    0]\n",
      " [  47   27    5  532   48    4    2   18  120    7   13    8    3    0\n",
      "     0    7    0    0]\n",
      " [   9    6    2   32  358    1    0   49    5    1   80   11    1    2\n",
      "     0    1    0    1]\n",
      " [  24    7    2    3    2  263    1    0    2    6    0   13    5    1\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    4    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    2    1    8   25    1    1  149    5    1    6    3    1    0\n",
      "    11    0    1    0]\n",
      " [   0    0    0    2    0    0    0    0    1    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   6    1    0    0    0    0    0    0    0   41    0    5   11    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    7    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0    0    0    8    0    0\n",
      "     0    0    0    0]\n",
      " [   0    1    0    1    1    0    0    0    0    1    0    0    1    1\n",
      "     0    1    1    0]\n",
      " [   0    0    0    0    1    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    1    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.7794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stochastic Gradient Descent</th>\n",
       "      <td>0.7739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Neighbors</th>\n",
       "      <td>0.6963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.6594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernoulli</th>\n",
       "      <td>0.6458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.2807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Accuracy_Score\n",
       "Logistic Regression                  0.7794\n",
       "Stochastic Gradient Descent          0.7739\n",
       "K-Neighbors                          0.6963\n",
       "Decision Tree                        0.6594\n",
       "Bernoulli                            0.6458\n",
       "Gaussian                             0.2807"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo_test(x.toarray(),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4783df6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
